{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import numpy as np\n",
    "import time\n",
    "import tiktoken\n",
    "openai.api_key = ''\n",
    "import concurrent.futures\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('classified_data_complete_final.csv')\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>governor</th>\n",
       "      <th>tokens</th>\n",
       "      <th>Relevant</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-24</td>\n",
       "      <td>Hike, Skip, or Pause?</td>\n",
       "      <td>Thank you, Peter, and thank you for the opport...</td>\n",
       "      <td>Governor Christopher J. Waller</td>\n",
       "      <td>1000</td>\n",
       "      <td>Inflation</td>\n",
       "      <td>Inflation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-05-24</td>\n",
       "      <td>Hike, Skip, or Pause?</td>\n",
       "      <td>is running too high. Likewise, narrower defin...</td>\n",
       "      <td>Governor Christopher J. Waller</td>\n",
       "      <td>1000</td>\n",
       "      <td>Inflation, Interest Rates</td>\n",
       "      <td>Inflation, Interest Rates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-05-24</td>\n",
       "      <td>Hike, Skip, or Pause?</td>\n",
       "      <td>are three options: hike, skip, or pause. Let ...</td>\n",
       "      <td>Governor Christopher J. Waller</td>\n",
       "      <td>642</td>\n",
       "      <td>The speech mentions inflation, interest rates,...</td>\n",
       "      <td>Inflation, Interest Rates, Economic Growth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                  title  \\\n",
       "0 2023-05-24  Hike, Skip, or Pause?   \n",
       "1 2023-05-24  Hike, Skip, or Pause?   \n",
       "2 2023-05-24  Hike, Skip, or Pause?   \n",
       "\n",
       "                                                text  \\\n",
       "0  Thank you, Peter, and thank you for the opport...   \n",
       "1   is running too high. Likewise, narrower defin...   \n",
       "2   are three options: hike, skip, or pause. Let ...   \n",
       "\n",
       "                         governor  tokens  \\\n",
       "0  Governor Christopher J. Waller    1000   \n",
       "1  Governor Christopher J. Waller    1000   \n",
       "2  Governor Christopher J. Waller     642   \n",
       "\n",
       "                                            Relevant  \\\n",
       "0                                          Inflation   \n",
       "1                          Inflation, Interest Rates   \n",
       "2  The speech mentions inflation, interest rates,...   \n",
       "\n",
       "                                        clean  \n",
       "0                                   Inflation  \n",
       "1                   Inflation, Interest Rates  \n",
       "2  Inflation, Interest Rates, Economic Growth  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_classify = df[df['clean'] != \"No Topic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sw/lwscf3w57bz06p9m9g2_5q1r0000gn/T/ipykernel_77846/1465617380.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_to_classify[\"score\"] = np.nan\n"
     ]
    }
   ],
   "source": [
    "df_to_classify[\"score\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make a single API call to OpenAI's API\n",
    "def make_api_call(speech):\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant specialized in identifying sentiment in Federal Reserve Speeches. Please label each speech only with these 5 labels: Dovish, Mostly Dovish, Neutral, Mostly Hawkish, Hawkish.\"},\n",
    "                {\"role\": \"user\", \"content\": \"'We believe inflation is temporary and we will keep interest rates low to support economic recovery.'\\n Sentiment (Dovish, Mostly Dovish, Neutral, Mostly Hawkish, Hawkish):\"},\n",
    "                {\"role\": \"assistant\", \"content\": \"Dovish\"},\n",
    "                {\"role\": \"user\", \"content\": \"'The current economic situation may require us to maintain a lower interest rate for a while.'\\n Sentiment (Dovish, Mostly Dovish, Neutral, Mostly Hawkish, Hawkish):\"},\n",
    "                {\"role\": \"assistant\", \"content\": \"Mostly Dovish\"},\n",
    "                {\"role\": \"user\", \"content\": \"'We're monitoring the situation carefully and will adjust monetary policy as needed.'\\n Sentiment (Dovish, Mostly Dovish, Neutral, Mostly Hawkish, Hawkish):\"},\n",
    "                {\"role\": \"assistant\", \"content\": \"Neutral\"},\n",
    "                {\"role\": \"user\", \"content\": \"'Given the positive economic indicators, it may be necessary to start considering raising interest rates.'\\n Sentiment (Dovish, Mostly Dovish, Neutral, Mostly Hawkish, Hawkish):\"},\n",
    "                {\"role\": \"assistant\", \"content\": \"Mostly Hawkish\"},\n",
    "                {\"role\": \"user\", \"content\": \"'The risk of inflation is high, it's critical to increase interest rates immediately.'\\n Sentiment (Dovish, Mostly Dovish, Neutral, Mostly Hawkish, Hawkish):\"},\n",
    "                {\"role\": \"assistant\", \"content\": \"Hawkish\"},\n",
    "                {\"role\": \"user\", \"content\": f\"\"\"Speech: \"{speech}\" \\n Sentiment (Dovish, Mostly Dovish, Neutral, Mostly Hawkish, Hawkish):\"\"\"}],\n",
    "            temperature=1,\n",
    "            max_tokens=30\n",
    "        )\n",
    "        return response['choices'][0]['message']['content'].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while making API call: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def process_dataframe(df, x=20, y=2):\n",
    "    \"\"\"\n",
    "    Processes the given DataFrame by making API calls in batches.\n",
    "    \n",
    "    :param df: DataFrame to process.\n",
    "    :param x: Number of API calls to make at once.\n",
    "    :param y: Time to wait between batches in minutes.\n",
    "    \"\"\"\n",
    "    # Calculate the number of batches\n",
    "    num_batches = math.ceil(len(df) / x)\n",
    "\n",
    "    # Loop through the DataFrame in batches\n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * x\n",
    "        end_idx = start_idx + x\n",
    "        \n",
    "        # Select the rows where \"Relevant\" is NaN\n",
    "        \n",
    "        rows_to_update = df.iloc[start_idx:end_idx][df['score'].isna().iloc[start_idx:end_idx]]\n",
    "        \n",
    "        # Break the loop if there are no more NaN values\n",
    "        if rows_to_update.empty:\n",
    "            break\n",
    "\n",
    "        # Making X API calls concurrently\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=x) as executor:\n",
    "            results = list(executor.map(make_api_call, rows_to_update['text']))\n",
    "\n",
    "        # Insert the results into the 'Relevant' column of the DataFrame\n",
    "        df.loc[rows_to_update.index, 'score'] = results\n",
    "        \n",
    "        # Wait for y minutes before the next batch\n",
    "        df.to_csv(\"fixed.csv\", index=False)\n",
    "        print(f\"currently classifying rows:{start_idx} to {end_idx}\")\n",
    "        time.sleep(y * 60)\n",
    "\n",
    "    # Return the processed DataFrame\n",
    "    return df\n",
    "\n",
    "# Process the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently classifying rows:0 to 20\n",
      "currently classifying rows:20 to 40\n",
      "currently classifying rows:40 to 60\n",
      "currently classifying rows:60 to 80\n",
      "currently classifying rows:80 to 100\n",
      "currently classifying rows:100 to 120\n",
      "An error occurred while making API call: The server is overloaded or not ready yet.\n",
      "currently classifying rows:120 to 140\n",
      "currently classifying rows:140 to 160\n",
      "currently classifying rows:160 to 180\n",
      "currently classifying rows:180 to 200\n",
      "currently classifying rows:200 to 220\n",
      "currently classifying rows:220 to 240\n",
      "currently classifying rows:240 to 260\n",
      "currently classifying rows:260 to 280\n",
      "currently classifying rows:280 to 300\n",
      "currently classifying rows:300 to 320\n",
      "An error occurred while making API call: The server is overloaded or not ready yet.\n",
      "currently classifying rows:320 to 340\n",
      "currently classifying rows:340 to 360\n",
      "currently classifying rows:360 to 380\n",
      "An error occurred while making API call: The server is overloaded or not ready yet.\n",
      "currently classifying rows:380 to 400\n",
      "currently classifying rows:400 to 420\n",
      "currently classifying rows:420 to 440\n",
      "currently classifying rows:440 to 460\n",
      "currently classifying rows:460 to 480\n",
      "currently classifying rows:480 to 500\n",
      "currently classifying rows:500 to 520\n",
      "currently classifying rows:520 to 540\n",
      "An error occurred while making API call: The server is overloaded or not ready yet.\n",
      "currently classifying rows:540 to 560\n",
      "currently classifying rows:560 to 580\n",
      "currently classifying rows:580 to 600\n",
      "currently classifying rows:600 to 620\n",
      "currently classifying rows:620 to 640\n",
      "currently classifying rows:640 to 660\n",
      "currently classifying rows:660 to 680\n",
      "currently classifying rows:680 to 700\n",
      "currently classifying rows:700 to 720\n",
      "currently classifying rows:720 to 740\n",
      "currently classifying rows:740 to 760\n",
      "An error occurred while making API call: The server is overloaded or not ready yet.\n",
      "currently classifying rows:760 to 780\n",
      "currently classifying rows:780 to 800\n",
      "currently classifying rows:800 to 820\n",
      "currently classifying rows:820 to 840\n",
      "currently classifying rows:840 to 860\n",
      "currently classifying rows:860 to 880\n",
      "currently classifying rows:880 to 900\n",
      "currently classifying rows:900 to 920\n",
      "currently classifying rows:920 to 940\n",
      "An error occurred while making API call: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 21 Jul 2023 14:05:28 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7ea3f828ca71a32b-FCO', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "currently classifying rows:940 to 960\n",
      "currently classifying rows:960 to 980\n",
      "currently classifying rows:980 to 1000\n",
      "An error occurred while making API call: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 21 Jul 2023 14:17:48 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7ea40a348d29a265-FCO', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "currently classifying rows:1000 to 1020\n",
      "currently classifying rows:1020 to 1040\n",
      "currently classifying rows:1040 to 1060\n",
      "An error occurred while making API call: The server is overloaded or not ready yet.\n",
      "currently classifying rows:1060 to 1080\n",
      "An error occurred while making API call: The server is overloaded or not ready yet.\n",
      "currently classifying rows:1080 to 1100\n",
      "currently classifying rows:1100 to 1120\n",
      "currently classifying rows:1120 to 1140\n",
      "currently classifying rows:1140 to 1160\n",
      "An error occurred while making API call: The server is overloaded or not ready yet.\n",
      "currently classifying rows:1160 to 1180\n",
      "currently classifying rows:1180 to 1200\n",
      "currently classifying rows:1200 to 1220\n",
      "currently classifying rows:1220 to 1240\n",
      "currently classifying rows:1240 to 1260\n",
      "currently classifying rows:1260 to 1280\n",
      "currently classifying rows:1280 to 1300\n",
      "currently classifying rows:1300 to 1320\n",
      "An error occurred while making API call: The server is overloaded or not ready yet.\n",
      "currently classifying rows:1320 to 1340\n",
      "currently classifying rows:1340 to 1360\n",
      "currently classifying rows:1360 to 1380\n",
      "currently classifying rows:1380 to 1400\n",
      "currently classifying rows:1400 to 1420\n",
      "currently classifying rows:1420 to 1440\n",
      "currently classifying rows:1440 to 1460\n",
      "currently classifying rows:1460 to 1480\n",
      "currently classifying rows:1480 to 1500\n",
      "currently classifying rows:1500 to 1520\n",
      "currently classifying rows:1520 to 1540\n",
      "An error occurred while making API call: The server is overloaded or not ready yet.\n",
      "currently classifying rows:1540 to 1560\n",
      "currently classifying rows:1560 to 1580\n",
      "currently classifying rows:1580 to 1600\n",
      "An error occurred while making API call: The server is overloaded or not ready yet.\n",
      "currently classifying rows:1600 to 1620\n",
      "currently classifying rows:1620 to 1640\n",
      "An error occurred while making API call: The server is overloaded or not ready yet.\n",
      "currently classifying rows:1640 to 1660\n",
      "An error occurred while making API call: The server is overloaded or not ready yet.\n",
      "currently classifying rows:1660 to 1680\n",
      "currently classifying rows:1680 to 1700\n",
      "currently classifying rows:1700 to 1720\n",
      "currently classifying rows:1720 to 1740\n",
      "currently classifying rows:1740 to 1760\n",
      "currently classifying rows:1760 to 1780\n",
      "currently classifying rows:1780 to 1800\n",
      "currently classifying rows:1800 to 1820\n",
      "currently classifying rows:1820 to 1840\n",
      "currently classifying rows:1840 to 1860\n",
      "currently classifying rows:1860 to 1880\n",
      "currently classifying rows:1880 to 1900\n",
      "currently classifying rows:1900 to 1920\n"
     ]
    }
   ],
   "source": [
    "scored_df = process_dataframe(df_to_classify, x=20, y=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score\n",
       "Neutral                                                                                                                                                                                          1151\n",
       "Mostly Dovish                                                                                                                                                                                     497\n",
       "Mostly Hawkish                                                                                                                                                                                    187\n",
       "Dovish                                                                                                                                                                                             34\n",
       "Hawkish                                                                                                                                                                                            32\n",
       "Mostly Neutral                                                                                                                                                                                      2\n",
       "The sentiment of this speech is Mostly Dovish.                                                                                                                                                      2\n",
       "The provided speech does not contain enough information related to monetary policy or economic outlook to determine sentiment accurately.                                                           1\n",
       "The sentiment of the speech is Mostly Hawkish.                                                                                                                                                      1\n",
       "The sentiment of this speech cannot be determined without further context.                                                                                                                          1\n",
       "This speech does not provide clear sentiment towards future monetary policy. The speech primarily discusses the tools and effects of open market purchases and forward rate guidance, without       1\n",
       "This speech does not provide enough context or information to accurately determine the sentiment.                                                                                                   1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_df = pd.read_csv(\"classified_data_complete_final_scored.csv\")\n",
    "scored_df.value_counts(\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sw/lwscf3w57bz06p9m9g2_5q1r0000gn/T/ipykernel_77846/2738718033.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  scored_df['clean'][scored_df[\"clean\"].isna()] = scored_df['clean'][scored_df[\"clean\"].isna()].apply(clean_categories)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "date        0\n",
       "title       0\n",
       "text        0\n",
       "governor    0\n",
       "tokens      0\n",
       "Relevant    0\n",
       "clean       0\n",
       "score       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['Inflation', 'Interest Rates', 'Economic Growth', 'Employment', 'No Topic']\n",
    "\n",
    "def clean_categories(row):\n",
    "    # Check if the row is a string\n",
    "    if isinstance(row, str):\n",
    "        # Split the categories and strip whitespace\n",
    "        row_categories = [category.strip() for category in row.split(',')]\n",
    "        # Filter out any categories not in the acceptable list\n",
    "        row_categories = [category for category in row_categories if category in categories]\n",
    "        # If 'No Topic' is not the only category, remove it\n",
    "        if 'No Topic' in row_categories and len(row_categories) > 1:\n",
    "            row_categories.remove('No Topic')\n",
    "        # Join the categories back together\n",
    "        return ', '.join(row_categories)\n",
    "    else:\n",
    "        # If the row is not a string, return 'No Topic'\n",
    "        return 'No Topic'\n",
    "\n",
    "# Apply the function to the 'clean' column\n",
    "scored_df['clean'][scored_df[\"clean\"].isna()] = scored_df['clean'][scored_df[\"clean\"].isna()].apply(clean_categories)\n",
    "\n",
    "scored_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_df.to_csv(\"classified_data_final_scored_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
